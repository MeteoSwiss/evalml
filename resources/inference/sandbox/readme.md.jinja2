# Anemoi inference sandbox

This sandbox was automatically generated by [evalml](https://github.com/MeteoSwiss/evalml). It contains the information to run [this model]({{ run_mlflow_link }}):
{% if strict -%}
- checkpoint: `{{ checkpoint_path }}`
{%- else %}
- checkpoint path: `{{ checkpoint_path }}`
{%- endif %}
- python environment definition (`pyproject.toml` and `uv.lock`)
{% if image -%}
- inference environment squashfs image: `{{ image }}`
{%- endif %}

It is not intended to be used for production, but only as a development and testing environment.

## Usage
{% if image %}
To set up your python environment, you have two options: using the squashfs image (on Alps) or creating your own virtual environment.
Coming soon..
{% endif %}
To install the environment, run `uv sync`. Then activate it with `source .venv/bin/activate`.
You can now run a model with `anemoi-inference run config/config.yaml` (don't forget to do it on a GPU compute node).

## Developing anemoi packages
The anemoi dependencies specified in the `pyproject.toml` and `uv.lock` have pinned versions based on the provenance information in the checkpoint metadata, the exception being `anemoi-inference`. You can update your environment with editable installations of anemoi packages. For conveniency, we already included some under `lib` (the main branch on the GitHub repository at the moment of the creation of this sandbox). You can then simply install them with e.g.

```shell
uv add lib/anemoi-inference --editable
```

Note that you might have to relax some of the pinned dependencies in order to install the latest versions. In general, we recommend NOT to touch `anemoi-models` or `anemoi-graph`, as it is very likely that it will break your model. It should generally be safe to upgrade the other anemoi packages, but there's no real guarantee (if something breaks, you have something to work on).
